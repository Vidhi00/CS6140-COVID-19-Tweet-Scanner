{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8432542",
   "metadata": {},
   "source": [
    "## Sentiment Prediction using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf88a2d",
   "metadata": {},
   "source": [
    "Spacy is written in cython language, (C extension of Python designed to give C like performance to the python program). Hence is a quite fast library. spaCy provides a concise API to access its methods and properties governed by trained machine (and deep) learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffed13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14f848b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40964, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('COVID19 Tweets_clean2.csv', encoding = 'latin')\n",
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5234748c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advice Talk neighbour family exchange phone nu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coronavirus Australia Woolworths give elderly ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food stock one empty PLEASE panic THERE WILL E...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ready supermarket #COVID outbreak Not paranoid...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news region first confirmed COVID case came Su...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet           Sentiment\n",
       "0  advice Talk neighbour family exchange phone nu...            Positive\n",
       "1  Coronavirus Australia Woolworths give elderly ...            Positive\n",
       "2  food stock one empty PLEASE panic THERE WILL E...            Positive\n",
       "3  ready supermarket #COVID outbreak Not paranoid...  Extremely Negative\n",
       "4  news region first confirmed COVID case came Su...            Positive"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8767b0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 3, 2, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['Sentiment']= label_encoder.fit_transform(df['Sentiment'])\n",
    "  \n",
    "df['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a9bec33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advice Talk neighbour family exchange phone nu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coronavirus Australia Woolworths give elderly ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food stock one empty PLEASE panic THERE WILL E...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ready supermarket #COVID outbreak Not paranoid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news region first confirmed COVID case came Su...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0  advice Talk neighbour family exchange phone nu...          4\n",
       "1  Coronavirus Australia Woolworths give elderly ...          4\n",
       "2  food stock one empty PLEASE panic THERE WILL E...          4\n",
       "3  ready supermarket #COVID outbreak Not paranoid...          0\n",
       "4  news region first confirmed COVID case came Su...          4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ac95af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advice Talk neighbour family exchange phone nu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coronavirus Australia Woolworths give elderly ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food stock one empty PLEASE panic THERE WILL E...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ready supermarket #COVID outbreak Not paranoid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news region first confirmed COVID case came Su...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0  advice Talk neighbour family exchange phone nu...          4\n",
       "1  Coronavirus Australia Woolworths give elderly ...          4\n",
       "2  food stock one empty PLEASE panic THERE WILL E...          4\n",
       "3  ready supermarket #COVID outbreak Not paranoid...          0\n",
       "4  news region first confirmed COVID case came Su...          4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Tweet','Sentiment']].dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4090871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sense2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "486d0f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('advice Talk neighbour family exchange phone number create contact list phone number neighbour school employer chemist set online shopping account po adequate supply regular med order',\n",
       "  4),\n",
       " ('Coronavirus Australia Woolworths give elderly disabled dedicated shopping hour amid COVID outbreak',\n",
       "  4),\n",
       " ('food stock one empty PLEASE panic THERE WILL ENOUGH FOOD FOR EVERYONE take need Stay calm stay safe #COVID france #COVID #COVID #coronavirus #confinement #Confinementotal #ConfinementGeneral',\n",
       "  4),\n",
       " ('ready supermarket #COVID outbreak Not paranoid food stock litteraly empty The #coronavirus serious thing please panic cause shortage #CoronavirusFrance #restezchezvous #StayAtHome #confinement',\n",
       "  0),\n",
       " ('news region first confirmed COVID case came Sullivan County last week people flocked area store purchase cleaning supply hand sanitizer food toilet paper good report',\n",
       "  4)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conveting df to a list of tweets with sentiment values\n",
    "df['tuples'] = df.apply(lambda row: (row['Tweet'],row['Sentiment']), axis=1)\n",
    "train = df['tuples'].tolist()\n",
    "train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4986e",
   "metadata": {},
   "source": [
    "### Loading the data and model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e6ec6",
   "metadata": {},
   "source": [
    "We implemented a pipeline approach to automate all the processes involved in model building, which in turn is created by loading the models. There are different types of models provided in the package which contains the information about language – vocabularies, trained vectors, syntaxes and entities. We explored Tokenization, POS tagging, Dependency Parsing, Noun phrases and Word to Vector integration in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5aecfbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data and evaluating the tokenizer\n",
    "def load_data(limit=0, split=0.8):\n",
    "    train_data = train\n",
    "    np.random.shuffle(train_data)\n",
    "    train_data = train_data[-limit:]\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [{'POSITIVE': bool(y)} for y in labels]\n",
    "    split = int(len(train_data) * split)\n",
    "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 1e-8  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 1e-8  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}\n",
    "\n",
    "#(\"Number of texts to train from\",\"t\" , int)\n",
    "n_texts= 30000\n",
    "#You can increase texts count if you have more computational power.\n",
    "\n",
    "#(\"Number of training iterations\", \"n\", int))\n",
    "n_iter=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52d28807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.examples import sentences \n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed64d368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Covid Tweets data...\n",
      "Using 30000 examples (24000 training, 6000 evaluation)\n"
     ]
    }
   ],
   "source": [
    "# add the text classifier to the pipeline if it doesn't exist\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "\n",
    "textcat = nlp.add_pipe('textcat')\n",
    "\n",
    "# add label to text classifier\n",
    "textcat.add_label('POSITIVE')\n",
    "\n",
    "# load the dataset\n",
    "print(\"Loading Covid Tweets data...\")\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=n_texts)\n",
    "print(\"Using {} examples ({} training, {} evaluation)\"\n",
    "      .format(n_texts, len(train_texts), len(dev_texts)))\n",
    "train_data = list(zip(train_texts, [{'cats': cats} for cats in train_cats]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "539cb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [str(x[0]) for x in train_data if 'nan' in str(x[0]).lower() and len(str(x[0])) < 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f03704b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# textcat.add_label('Positive')\n",
    "textcat.add_label('NEGATIVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0cd846",
   "metadata": {},
   "source": [
    "These pipelines output a wide range of document properties such as – tokens, token’s reference index, part of speech tags, entities, vectors, sentiment, vocabulary etc. Next, we performed all the steps required to build the model and used our model to make predictions. For instance, our model was able to classify a review as either Positive or Negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training.example import Example\n",
    "import random\n",
    "\n",
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.create_optimizer()\n",
    "    print(\"Training the model...\")\n",
    "    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        examples = []\n",
    "        for text, annots in train_data:\n",
    "            examples.append(Example.from_dict(nlp.make_doc(text), annots))\n",
    "        nlp.initialize(lambda: examples)\n",
    "        for i in range(20):\n",
    "            random.shuffle(examples)\n",
    "            for batch in minibatch(examples, size=compounding(4., 32., 1.001)):\n",
    "                nlp.update(batch)\n",
    "        \n",
    "        try:\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                # evaluate on the dev data split off in load_data()\n",
    "                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "        except TypeError as e:\n",
    "            print(f\"Got Error :: '{e}'\\n Skipping this.\\n\")c            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90926475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support everyone who's suffering... We are in this together!! {'POSITIVE': 0.9988889098167419, 'NEGATIVE': 0.0011111637577414513}\n",
      "COVID-19 sucks!!! Gov's scam to rip off money... China should be responsible for this shit.. {'POSITIVE': 0.0008598110871389508, 'NEGATIVE': 0.9991401433944702}\n"
     ]
    }
   ],
   "source": [
    "# testing the trained model and predicting the test tweets\n",
    "\n",
    "# positive tweet\n",
    "test_text1 = \"Support everyone who's suffering... We are in this together!!\"\n",
    "# negative tweet\n",
    "test_text2=\"COVID-19 sucks!!! Gov's scam to rip off money... China should be responsible for this shit..\"\n",
    "doc = nlp(test_text1)\n",
    "print(test_text1, doc.cats)\n",
    "print('\\n\\n')\n",
    "doc = nlp(test_text2)\n",
    "print(test_text2, doc.cats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
